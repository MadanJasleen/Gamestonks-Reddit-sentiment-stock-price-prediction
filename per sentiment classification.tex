\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|c|c|}
    \hline
    \textbf{Model} & \textbf{Class} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-score} \\
    \hline
    \multirow{3}{*}{VADER} 
        & Positive & 0.80   &  0.71 & 0.75  \\
        & Negative & 0.12   & 0.31 & 0.18 \\
        & Neutral  & 0.52 & 0.41 & 0.46 \\
    \hline
    \multirow{3}{*}{finBERT- tone} 
        & Positive & 0.91 &  0.38  & 0.54 \\
        & Negative & 0.20 & 0.20 & 0.20 \\
        & Neutral  & 0.33  & 0.81 & 0.47 \\
    \hline
    \multirow{3}{*}{FinGPT v3} 
        & Positive & 0.89 & 0.33 & 0.48 \\
        & Negative & 0.40 & 0.22 & 0.29 \\
        & Neutral  & 0.30 & 0.86 & 0.45 \\
    \hline
    \multirow{3}{*}{Gemma-3} 
        & Positive & 0.80   &  0.99 & 0.88  \\
        & Negative & 0.79   & 0.42 & 0.55 \\
        & Neutral  & 0.86 & 0.46 & 0.60 \\

    \hline
\end{tabular}
\caption{\textit{The table presents per-class precision, recall, and F1-score for each sentiment class (Positive, Negative, Neutral) across different models (VADER, finBERT-tone, FinGPT v3, and Gemma-3) used for sentiment classification. Among the evaluated models, Gemma-3 consistently outperforms others across all sentiment classes, particularly in the Positive class with a high recall (0.99) and strong F1-score (0.88), indicating excellent sensitivity and balanced performance. While VADER shows moderate balance in performance, it struggles significantly with Negative sentiments (F1-score: 0.18). finBERT-tone and FinGPT v3 achieve high recall for Neutral class but suffer from low precision, resulting in moderate F1-scores. In contrast, Gemma-3 delivers more stable and higher scores across the board, demonstrating its robustness in sentiment classification tasks.}}
\label{tab:per_class_metrics}
\end{table}

